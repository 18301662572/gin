

# 知识点：

### 1.Map as querystring or postform parameters

```go
POST /post?ids[a]=1234&ids[b]=hello HTTP/1.1
Content-Type: application/x-www-form-urlencoded

names[first]=thinkerou&names[second]=tianou
func main() {
	router := gin.Default()

	router.POST("/post", func(c *gin.Context) {

		ids := c.QueryMap("ids")
		names := c.PostFormMap("names")

		fmt.Printf("ids: %v; names: %v", ids, names)
	})
	router.Run(":8080")
}
ids: map[b:hello a:1234], names: map[second:tianou first:thinkerou]
```



## 2.Upload Files

```go
//单个文件上传
func main() {
	router := gin.Default()
	// Set a lower memory limit for multipart forms (default is 32 MiB)
	// router.MaxMultipartMemory = 8 << 20  // 8 MiB
	router.POST("/upload", func(c *gin.Context) {
		// single file
		file, _ := c.FormFile("file")
		log.Println(file.Filename)

		// Upload the file to specific dst.
		// c.SaveUploadedFile(file, dst)

		c.String(http.StatusOK, fmt.Sprintf("'%s' uploaded!", file.Filename))
	})
	router.Run(":8080")
}

curl -X POST http://localhost:8080/upload \
  -F "file=@/Users/appleboy/test.zip" \
  -H "Content-Type: multipart/form-data"

//多个文件上传
func main() {
	router := gin.Default()
	// Set a lower memory limit for multipart forms (default is 32 MiB)
	// router.MaxMultipartMemory = 8 << 20  // 8 MiB
	router.POST("/upload", func(c *gin.Context) {
		// Multipart form
		form, _ := c.MultipartForm()
		files := form.File["upload[]"]

		for _, file := range files {
			log.Println(file.Filename)

			// Upload the file to specific dst.
			// c.SaveUploadedFile(file, dst)
		}
		c.String(http.StatusOK, fmt.Sprintf("%d files uploaded!", len(files)))
	})
	router.Run(":8080")
}

curl -X POST http://localhost:8080/upload \
  -F "upload[]=@/Users/appleboy/test1.zip" \
  -F "upload[]=@/Users/appleboy/test2.zip" \
  -H "Content-Type: multipart/form-data"
```



```go
您也可以指定必填字段。如果binding:"required"在绑定时使用字段修饰并且字段为空，则将返回错误。
// Binding from JSON
type Login struct {
	User     string `form:"user" json:"user" xml:"user"  binding:"required"`
	Password string `form:"password" json:"password" xml:"password" binding:"required"`
}


```



## Bind Uri

```go
package main

import "github.com/gin-gonic/gin"

type Person struct {
	ID string `uri:"id" binding:"required,uuid"`
	Name string `uri:"name" binding:"required"`
}

func main() {
	route := gin.Default()
	route.GET("/:name/:id", func(c *gin.Context) {
		var person Person
		if err := c.ShouldBindUri(&person); err != nil {
			c.JSON(400, gin.H{"msg": err})
			return
		}
		c.JSON(200, gin.H{"name": person.Name, "uuid": person.ID})
	})
	route.Run(":8088")
}

$ curl -v localhost:8088/thinkerou/987fbc97-4bed-5078-9f07-9141ba07c9f3
$ curl -v localhost:8088/thinkerou/not-uuid
```









## **3.日志Logger()是一个必要的中间件**



## 4.完整的GIN demo

```go
package main

import (
    "github.com/gin-gonic/gin"
    "net/http"
    "log"
    "fmt"
    "time"
    "gopkg.in/go-playground/validator.v8"
    "reflect"
    "github.com/gin-gonic/gin/binding"
)

func main() {
    router := gin.Default()

    router.Use()
    router.GET("/", func(c *gin.Context) {
        c.String(http.StatusOK, "It works")
    })

    router.POST("/form_post", func(c *gin.Context) {
        message := c.PostForm("message")
        nick := c.DefaultPostForm("nick", "anonymous")

        c.JSON(200, gin.H{
            "status":  "posted",
            "message": message,
            "nick":    nick,
        })
    })

    router.POST("/upload", func(c *gin.Context) {
        // single file
        file, _ := c.FormFile("file")
        log.Println(file.Filename)

        c.String(http.StatusOK, fmt.Sprintf("'%s' uploaded!", file.Filename))
    })

    router.LoadHTMLGlob("templates/*")
    router.GET("/upload", func(c *gin.Context) {
        c.HTML(http.StatusOK, "upload.html", gin.H{})
    })
    router.GET("/index", func(c *gin.Context) {
        c.HTML(http.StatusOK, "index.tmpl", gin.H{
            "title": "Main website",
        })
    })

    router.GET("/redict/google", func(c *gin.Context) {
        c.Redirect(http.StatusMovedPermanently, "https://google.com")
    })

    v1 := router.Group("/v1")

    v1.GET("/login", func(c *gin.Context) {
        c.String(http.StatusOK, "v1 login")
    })

    v2 := router.Group("/v2")

    v2.GET("/login", func(c *gin.Context) {
        c.String(http.StatusOK, "v2 login")
    })

    router.Use(MiddleWare())

    router.GET("/before", MiddleWare(), func(c *gin.Context) {
        request := c.MustGet("request").(string)
        c.JSON(http.StatusOK, gin.H{
            "middile_request": request,
        })
    })

    router.GET("/sync", func(c *gin.Context) {
        time.Sleep(5 * time.Second)
        log.Println("Done! in path" + c.Request.URL.Path)
    })

    router.GET("/async", func(c *gin.Context) {
        cCp := c.Copy()
        go func() {
            time.Sleep(5 * time.Second)
            log.Println("Done! in path" + cCp.Request.URL.Path)
        }()
    })

    router.GET("/user/:name", func(c *gin.Context) {
        name := c.Param("name")
        c.String(http.StatusOK, "Hello %s", name)
    })

    router.GET("/welcome", func(c *gin.Context) {
        firstname := c.DefaultQuery("firstname", "Guest")
        lastname := c.Query("lastname") // shortcut for     c.Request.URL.Query().Get("lastname")

        c.String(http.StatusOK, "Hello %s %s", firstname, lastname)
    })

    router.GET("/User/:name/*action",func (c *gin.Context){
        name:= c.Param("name")
        action := c.Param("action")
        message := name + "is" + action
        c.String(http.StatusOK,message)
    })

    router.GET("/welcome2", func(c *gin.Context) {
        firstname := c.DefaultQuery("firstname", "Guest")
        lastname := c.Query("lastname") // shortcut for     c.Request.URL.Query().Get("lastname")

        c.String(http.StatusOK, "Hello %s %s", firstname, lastname)
    })

    router.Static("/assets", "./assets")
    router.StaticFS("/more_static", http.Dir("my_file_system"))
    router.StaticFile("/favicon.ico", "./resources/favicon.ico")

    router.GET("/testing", startPage)

    if v, ok := binding.Validator.Engine().(*validator.Validate); ok {
        v.RegisterValidation("bookabledate", bookableDate)
    }

    router.GET("/bookable", getBookable)

    router.Run(":8001")
}

func MiddleWare() gin.HandlerFunc {
    return func(c *gin.Context) {
        fmt.Println("before middleware")
        c.Set("request", "clinet_request")
        c.Next()
        fmt.Println("before middleware")
    }
}

func startPage(c *gin.Context) {
    var person Person
    if c.ShouldBind(&person) == nil {
        log.Println(person.Name)
        log.Println(person.Address)
        log.Println(person.Birthday)
    }

    c.String(200, "Success")
}

type Person struct {
    Name     string    `form:"name"`
    Address  string    `form:"address"`
    Birthday time.Time `form:"birthday" time_format:"2006-01-02" time_utc:"1"`
}

type Booking struct {
    CheckIn  time.Time `form:"check_in" binding:"required,bookabledate" time_format:"2006-01-02"`
    CheckOut time.Time `form:"check_out" binding:"required,gtfield=CheckIn" time_format:"2006-01-02"`
}

func bookableDate(
    v *validator.Validate, topStruct reflect.Value, currentStructOrField reflect.Value,
    field reflect.Value, fieldType reflect.Type, fieldKind reflect.Kind, param string,
) bool {
    if date, ok := field.Interface().(time.Time); ok {
        today := time.Now()
        if today.Year() > date.Year() || today.YearDay() > date.YearDay() {
            return false
        }
    }
    return true
}

func getBookable(c *gin.Context) {
    var b Booking
    if err := c.ShouldBindWith(&b, binding.Query); err == nil {
        c.JSON(http.StatusOK, gin.H{"message": "Booking dates are valid!"})
    } else {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
    }
}
```

## 5.go get -u github.com/gin-gonic/gin

​		**-u :下载最新的**

```go
  r.LoadHTMLGlob("templates/**/*")
  **: 指tempaltes文件下所有的文件夹
  *： 指模板文件

```



## 6.Cookie跟Session (day12-021gin_demo-gincode)

http协议是无状态的额。

状态可以理解为客户端和服务器在某次会话中产生的数据，那无状态的就以为这些数据不会被保留。会话中产生的数据又是我们需要保存的，也就是说要“保持状态”。因此Cookie就是在这样一个场景下诞生。

**Cookie**: 由Web服务器创建的，将信息存储在客户端的数据文件。

​             特点：1.浏览器发送请求的时候，自动会携带该站点之前存储的Cookie信息

​						2.服务端可以设置Cookie数据

​						3.Cookie是针对单个域名的，不同域名之前的Cookie是独立的

​						4.Cookie数据可以配置过期时间，过期的Cookie数据会被系统清除

```go
设置Cookie：
func SetCookie(w ResponseWrite,cookie *Cookie)

获取Cookie
//解析并返回该请求的cookie头设置的所有cookie
fun (r *Request) Cookies() []*Cookie
//返回请求中名为name的cookie,如果未找到该cookie会返回nil,ErrNoCookire
func (r *Request) Cookie(name string) (*Cookie,error)

添加Cookie的方法
//AddCookie向请求中添加一个cookie
func (r *Request) AddCookie(c *Cookie)

```



**Session:** (day11-06gin-sesson)

基于HTTP协议的无状态特征，服务器根本就不知道访问者是“谁”。那么上述的Cookie就起到桥接的作用。用户登陆成功之后，我们在服务端为每个用户创建一个特定的session和一个唯一的标识，它们一一对应。**其中**：

​				**1.Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群，数据库，文件中；**

​				**2.唯一标识通常称为Session ID 会写入用户的Cookie中**

这样该用户后续再次访问时，请求会自动携带Cookie数据（其中包含了`Session ID`），服务器通过该`Session ID`就能找到与之对应的Session数据，也就知道来的人是“谁”。

**总结：**

​		Cookie弥补了HTTP无状态的不足，让服务器知道来的人是“谁”；但是Cookie以文本的形式保存在本地，自身安全性较差；所以我们就通过Cookie识别不同的用户，对应的在服务端为每个用户保存一个Session数据，该Session数据中能够保存具体的用户数据信息。



![](C:\Users\Administrator\Desktop\images\gin-session.png)

### Session中间件

```
老师开源的代码：https://github.com/Q1mi/ginsession
```

​		**1.内存版Session中间件实现**

​				**Session服务分成两部分：**

​					1.大仓库  --》单例模式

​					2.session data -->每个用户对应自己的session data

​		**2.Redis版Session中间件实现**

​		**3.mysql版Session中间件实现**			





# 7.Redis  [书籍<<Redis实战>>]

支持的数据结构多样！

​			strings、hashs、lists、sets、带范围查询的排序集合（sorted sets）、位图（bitmaps）、hyperloglogs、。。。

**应用场景：**

​			1.缓存系统，减轻主数据库（MYSQL）的压力

​			2.计数场景，比如：微博、抖音中的关注数和粉丝数

​			3.热门排行榜，需要排序的场景特别适合使用ZSET

​			4.利用LIST可以实现队列的功能。

**与Memcached比较**

​		memcached中的值只支持简单的字符串，Redis支持更丰富的5种数据结构类型。

​		redis性能比Mencached好很多，Redis支持RDB持久化和AOF持久化。Redis支持 master/slave模式。

​	官网：**http://www.redis.cn/**   

​    教程：**https://www.runoob.com/redis/redis-install.html**

​	**reids不推荐在windows平台使用，一般推荐linux平台使用**



## 8.MongoDB

​		没有学习



## 9.NSQ

​		目前比较流行的一个分布式的消息队列。

​		是Go语言编写的一个开源的实时分布式内存消息队列，其性能十分优异。

​		**优势：**

​				1.NSQ提倡分布式和分散的拓扑，没有单点故障，支持容错和高可用性，并提供可靠的消息支付保证

​				2.NSQ支持横向扩展，没有任何集中式代理，

​				3.NSQ易于配置和部署，并且内置了管理界面。

​		**特性:**

​				1.消息默认不持久化，可以配置成持久化模式。nsq采用的方式是 内存+硬盘 的模式，当内存到达一定程度时就会将数据持久化到硬盘。

​						a.如果将 --men-queue-size 设置为0，所有的消息将会存储到磁盘

​						b.服务器重启时也会将当时在内存中的消息持久化。

​				2.每条消息至少传递一次

​				3.消息不保证有序

​		**常用组件：**

​				1.**nsqd**： 是一个守护进程，他**接收**、**排队**并向客户端**发送**消息。

​				2.**nsqlookupd**:  维护所有的nsdq状态、提供**服务发现**的守护进程。

​				3.**nsqadmin**:  一个实时监控集群状态、执行各种管理任务的**Web管理平台**



​		**服务搭建**

```go
启动 nsqd 指定 -broadcast-address=127.0.0.1 来配置广播地址：
nsqd -broadcast-address=127.0.0.1

启动 nsqd，如果是在搭配 nsqlookupd 使用的模式下,需要首先指定 nsqlookupd 地址：
1.启动 nsqlookupd   
命令：nsqlookupd
2.启动nsqd
命令：nsqd -broadcast-address=127.0.0.1 -lookupd-tcp-address=127.0.0.1:4160
如果是部署了多个nsqlookupd节点的集群，那还可以指定多个-lookupd-tcp-address。

启动 nsqadmin 指定 nsqlookupd 地址：
nsqadmin -lookupd-http-address=127.0.0.1:4161

```

```go
在192.168.42.133虚拟机上搭建服务：
1.启动 nsqlookupd
nsqlookupd
2.启动nsqd
nsqd -broadcast-address=192.168.42.133 -lookupd-tcp-address=192.168.42.133:4160
3.启动nsqadmin
nsqadmin -lookupd-http-address=192.168.42.133:4161

```



**访问服务**

​			访问虚拟机的nsqadmin网站：[http://192.168.42.133:4171/] 





## 10.HTTP ：

**网站：**[https://www.runoob.com/http/http-tutorial.html]

### HTTP状态码分类

| 分类 | 分类描述                                       |
| :--- | :--------------------------------------------- |
| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |

### **HTTP状态码列表:**

| **301** | **Moved Permanently**     | **永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替** |
| ------- | ------------------------- | ------------------------------------------------------------ |
| **302** | **Found**                 | **临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI** |
| **200** | **OK**                    | **请求成功**                                                 |
| **404** | **Not Found**             | **请求的资源（网页等）不存在**                               |
| **500** | **Internal Server Error** | **内部服务器错误**                                           |



## 



## 11.snowflake 雪花算法（每个雪花都不一样，所以生成的id不一样）

```
go get github.com/sony/sonyflake
```



**分布式的ID生成，保证数据的趋势是从大到小，不冲突的，即ID 是趋势递增的**

**高性能，生成的ID是全局唯一的，整型的，64位的long型数据，在数据库中应该用大于64位的数字类型的字段来保存该值，比如在Mysql中应该使用BIGINT.**



**算法：**

![](C:\Users\Administrator\Desktop\images\snowflake-64bit.png)

**缺点：**

​		1.依赖机器时钟，如果机器时钟回拨，会导致重复ID生成；（所以必须要给机器做NTP服务）

​		2.在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，有时候会出现不是全局递增的情况。（此缺点可以忽略，一般ID 趋势递增就可以了，~90%的需求都只要求趋势递增）

**snowflake 官方文档中明确要求必须配置NTP（网络时间协议）,并且NTP配置成不可向后调整的模式**

**NTP服务器**【Network Time Protocol（NTP）】是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源（如石英钟，GPS等等)做同步化，它可以提供高精准度的时间校正（LAN上与标准间差小于1毫秒，WAN上几十毫秒），且可介由加密确认的方式来防止恶毒的协议攻击。



## 12.goxorm 数据库映射

参考网站：[https://www.cnblogs.com/liuzhongchao/p/9497326.html]

​		官网：[https://gitea.com/xorm/xorm]



## 13.Go性能调优 ？？？最后看



## 14.性能测试及火焰图 ？？？最后看



## 15.⽇志收集客户端

![](C:\Users\Administrator\Desktop\images\log收集系统架构图.png)

**LogAgent：⽇志收集客户端，⽤来收集服务器上的⽇志。**

**Kafka：⾼吞吐量的分布式队列（Linkin开发，apache顶级开源项⽬）**

**ElasticSearch：开源的搜索引擎，提供基于HTTP RESTful的web接⼝。**

**Kibaba：开源的ES数据分析和可视化⼯具。**

**Hadoop：分布式计算框架，能够对⼤量数据进⾏分布式处理的平台。**

**Storm：⼀个免费并开源的分布式实时计算系统。**



**将学到的技能**
	**1.服务端agent开发**
	**2.后端服务组件开发Kafka和zookeeper的使⽤**

​	**3.ES和Kibana的使⽤**
​	**4.etcd的使⽤**



## 16.kafka

​		kafka是一个分布式数据流平台，可以运行在单台服务器上，也可以在多台服务器上部署形成集群。他提供了发布和订阅功能，使用者可以发送数据到kafka中，也可以从kafka中读取数据（以便进行后续的处理）kafka具有高吞吐，低延迟，高容错的特点

![](C:\Users\Administrator\Desktop\images\KafkaCluster.png)

​      **两个负载**：一个是Partition 分区，即接收负载，提高kafka的吞吐量。将topic数据放到不同的Partiton中，一个Broker的同一个topic下的 不同Partition的数据是不可以重复的。Partition的表现形式是一个一个的文件夹。

​						一个是Consumer Group，即消费负载。将多个消费者组成一个消费组。同一个Partition 分区的数据只能被同一个消费组中的某个消费者消费。即同一个消费组中的消费者可以消费同一个topic不同分区的数据，也是为了提高kafka的吞吐量

​	**Replication 备胎**/副本：  每个分区都有多个副本，副本的作用是做备胎。当一个Leader挂了，会选择一个备胎（Follower）上位做Leader。follower跟Leader绝对在不同的机器上，同一个机器对同一分区也只能存放一个副本。                                   Broker:部署了kafka实例的服务器节点，多个Broker做备份

​	**使用场景：**	

​			**消息队列（MQ）、追踪网站活动**：（Kafka最出就是被设计用来进行网站活动（比如PV、 UV、搜索记录等）的追踪。可以将不不同的活动放⼊入不不同的主题，供后续的实时计算、实时监控等程序使用，也可以将数据导入到数据仓库中进行后续的离线处理理和生成报表等。） 、**Metrics(传输监控数据)、日志聚合**	

**启动Zookpper:  在zookeeper目录执行  bin\zkServer.cmd**

**启动kafka服务，执行：bin\windows\kafka-server-start.bat config\server.properties（前提，先启动zookeeper服务）**

**cmd命令开启kafka消费者：**

**执行：bin\windows\kafka-console-consumer.bat --bootstrap-server 127.0.0.1:9092 --topic shopping --from-beginning**



**kafka生产者：（启用go mod ,因为sarama 使用的是v1.19的版本，需要在go mod里面指定版本号）**

**1.创建gomod：go mod init**

**2.加载引用包：go mod tidy -v**

**注：给生成文件重命名： go build -o rename.exe  (rename为新的名字)**

```go
//基于sarama第三方库开发的 kafka client,往kafka里面发送消息

import (
	"fmt"
	"github.com/Shopify/sarama"
)

func main() {
	//1.生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          //Ack 设置生产者发送完数据是否需要leader和follower都确认
	config.Producer.Partitioner = sarama.NewRandomPartitioner //partition 新选择一个分区partition
	config.Producer.Return.Successes = true                   //确认 成功交付的消息将在success channel返回

	//2.连接kafka
	client, err := sarama.NewSyncProducer([]string{"192.168.42.133:9092"}, config)
	if err != nil {
		fmt.Println("producer closed,err:", err)
		return
	}
	defer client.Close()

	//3.封装消息
	msg := &sarama.ProducerMessage{}
	msg.Topic = "shopping"
	msg.Value = sarama.StringEncoder("this is a test log")

	//4.发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send msg failed,err:", err)
		return
	}
	fmt.Printf("分区pid:%v 偏移offset:%v\n", pid, offset)
}

```

**tailf包：实时获取某个文件信息，实时输出**

```go

//tailf包一直接受文件中的消息

import (
	"fmt"
	"github.com/hpcloud/tail"
	"time"
)

func main() {
	filename := `./xx.log`
	config := tail.Config{
		ReOpen:   true,
		Follow:   true,
		Location: &tail.SeekInfo{Offset: 0, Whence: 2}, MustExist: false,
		Poll: true,
	}

	//1. 打开文件开始读取数据
	tails, err := tail.TailFile(filename, config)
	if err != nil {
		fmt.Printf("tail %s failed,err:%v\n", filename, err)
		return
	}

	//2.读取数据
	var (
		msg *tail.Line
		ok  bool
	)
	for {
		msg, ok = <-tails.Lines //chan tail.Line
		if !ok {
			fmt.Printf("tail file close reopen,filename:%s\n", tails.Filename)
			time.Sleep(time.Second) //读取出错，等一秒
			continue
		}
		fmt.Println("msg:", msg.Text)
	}
}
```



**kafka消费：**

```go
package main

import (
	"fmt"
	"github.com/Shopify/sarama"
	"sync"
)

// kafka consumer(消费者)

func main() {
	// 创建新的消费者
	consumer, err := sarama.NewConsumer([]string{"192.168.42.133:9092"}, nil)
	if err != nil {
		fmt.Printf("fail to start consumer, err:%v\n", err)
		return
	}
	// 拿到指定topic下面的所有分区列表
	partitionList, err := consumer.Partitions("web_log") // 根据topic取到所有的分区
	if err != nil {
		fmt.Printf("fail to get list of partition:err%v\n", err)
		return
	}
	fmt.Println(partitionList)
	var wg sync.WaitGroup
	for partition := range partitionList { // 遍历所有的分区
		// 针对每个分区创建一个对应的分区消费者
		pc, err := consumer.ConsumePartition("web_log", int32(partition), sarama.OffsetNewest)
		if err != nil {
			fmt.Printf("failed to start consumer for partition %d,err:%v\n",
				partition, err)
			return
		}
		defer pc.AsyncClose()
		// 异步从每个分区消费信息
		wg.Add(1)
		go func(sarama.PartitionConsumer) {
			for msg := range pc.Messages() {
				fmt.Printf("Partition:%d Offset:%d Key:%s Value:%s",
					msg.Partition, msg.Offset, msg.Key, msg.Value)
			}
		}(pc)
	}
	wg.Wait()
}
```





## 17.Zookeeper

​		是一个分布式的，开放源码的分布式应用程序协调服务，是集群的管理者，监视着集群中各个节点的状态，根据节点提交的反馈进行下一步合理操作。最终将简单易用的接口和性能高效、功能稳定的系统提供给用户。

**启动Zookpper:  在zookeeper目录执行  bin\zkServer.cmd**

​	

## 19.etcd

​		**类似于zookeeper(java), etcd\consul(goland)**

​		**etcd是使用Go语言开发的一个开源的、高可用的分布式key-value存储系统，可以用于配置共享		和服务的注册和发现。** 

​		**特点：**

​			1.完全复制：集群中的每个节点都可以使用完整的存档

​			2.高可用性：etcd可用于避免硬件的单点故障或网络问题

​			3.一致性：每次读取都会返回跨多主机的最新写入

​			4.简单：包括一个定义良好、面向用户的API（gRPC）

​			5.安全：实现了带有可选的客户端证书身份验证的自动化TLS

​			6.快速: 每秒10000次写入的基准速度

​			7.可靠：使用Raft 算法实现了强一致，高可用的服务存储目录

​		**应用场景**

​			1.服务发现

​			2.配置中心

​			3.分布式锁

​		**与zookeeper比较**

​				优点：简单（部署简单，http作为接口，Raft算法保证强一致性易于理解）；数据持久化；安全（支持SSL客户端安全认证）。

​				zookeeper: 复杂（部署维护复杂）；java编写（不容易维护）；发展缓慢

​		**架构**

​				![](C:\Users\Administrator\Desktop\images\etcd架构.png)

![](C:\Users\Administrator\Desktop\images\etcd架构Deatils.png)

​	**etcd集群搭建**

​			（见学习笔记文件夹内下载的博客）

​	**etcd使用：**

1.开启服务：(单机版)

```go
直接启动
命令：etcd.exe

注：etcd默认监听的是localhost的2379端口，既只监听了lo设备，这样会导致启动后集群中的其他机器无法访问
因此我们可以在启动的时候将默认的localhost改成0.0.0.0,确保etcd监听了所有网卡。
命令：etcd -listen-client-urls="http://0.0.0.0:2379" --advertise-client-urls="http://0.0.0.0:2379"

注意：etcd有要求，如果--listen-client-urls被设置了，那么就必须同时设置--advertise-client-urls，所以即使设置和默认相同，也必须显式设置
我们来使用curl来测试一下，是否可以远程访问，这里我的机器IP是192.168.42.133

?  ~ curl -L  http://192.168.42.133:2379/version
{"etcdserver":"3.3.12","etcdcluster":"3.3.0"}
```

2.客户端连接命令

```go
etcdctl.exe --endpoints=192.168.42.133:2379 put name "nazhe"
etcdctl.exe --endpoints=192.168.42.133:2379  get name

因为默认的 etcdctrl 使用的时v2版本的命令。没有 put 命令，先设置环境变量etcdctl_api=3来使用v3版本的api, 在使用客户端命令。（get 也同样需要设置版本）
命令：SET ETCDCTL_API=3
```

   **操作**

​		**1.put、get 操作**

```go
import (
	"fmt"
	"go.etcd.io/etcd/clientv3"
	"golang.org/x/net/context"
	"time"
)

//代码连接etcd

func main() {
	cli, err := clientv3.New(clientv3.Config{
		Endpoints:   []string{"192.168.42.133:2379"},
		DialTimeout: time.Second * 5,
	})
	if err != nil {
		fmt.Printf("connect to etcd failed,err:%v\n",err)
		return
	}
	defer cli.Close()

	//put
	ctx,cancel := context.WithTimeout(context.Background(),time.Second)
	_,err= cli.Put(ctx,"s4","this is a test")
	if err != nil {
		fmt.Printf("put to etcd failed,err:%v\n",err)
		return
	}
	cancel()

	//get
	ctx,cancel = context.WithTimeout(context.Background(),time.Second)
	gr,err:=cli.Get(ctx,"s4")
	if err != nil {
		fmt.Printf("get from etcd failed,err:%v\n",err)
		return
	}
	for _,ev :=range gr.Kvs{
		fmt.Printf("key:%s value:%s\n",ev.Key,ev.Value)
	}
	cancel()
}
```



​		**2.watch操作** 

​			**监控etcd中key的变化（创建、更改、删除）**



## 20.日志收集的agent开发(项目）

**完整项目及备注:**[F:\Learn\Go\GOWork\src\code.oldbody.com\studygolang\mylearn\11logagent_all]

​			**1.配置文件版logagent**

​					**获取ini配置：**go-ini

​					[https://github.com/go-ini/ini]

​					[https://ini.unknwon.io/]

​					**用etcd存储要收集的日志项，使用json格式**

​			**2.logagent使用etcd管理收集项**

​					程序启动之后，拉取了最新的配置之后，就应该派一个小弟去监控etcd中   collect_log_conf这个key的变化

​					![](C:\Users\Administrator\Desktop\images\logagent.png)

​				**3.每台服务器上的logagent的日志收集项可能都不一致，我们需要让logagent去etcd中根据ip获取自己的配置**

​						1.修改配置项 collect_key=collect_log_%s_conf

​						2.获取本机ip

​						3.将etcd获取日志收集配置项的key中的%s替换成本机ip

​						注：etcd 通过key获取的时候需要在key里面加上本机ip  

​								(gr, err := cli.Get(ctx, "collect_log_192.168.42.133_conf"))

## 	

## **21.获取系统信息--gopsutil**

​		**gopsutil**： psutil 是一个跨平台进程和系统监控的Python库，而gopsutil 是其Go语言版本的实现。Go语言部署简单、性能好的特点非常适合做一些诸如采集系统信息和监控的服务，本文介绍的[gopsutil](https://github.com/shirou/gopsutil)库是知名Python库：[psutil](https://github.com/giampaolo/psutil)的一个Go语言版本的实现。

​		[https://www.liwenzhou.com/posts/Go/go_gopsutil/]

​		**安装：**go get github.com/shirou/gopsutil

​		**使用：**

​				**1.CPU**

```go
import "github.com/shirou/gopsutil/cpu"

// 采集CPU相关信息
func getCpuInfo() {
	cpuInfos, err := cpu.Info()
	if err != nil {
		fmt.Printf("get cpu info failed, err:%v", err)
	}
	for _, ci := range cpuInfos {
		fmt.Println(ci)
	}
	// CPU使用率
	for {
		percent, _ := cpu.Percent(time.Second, false)
		fmt.Printf("cpu percent:%v\n", percent)
	}
}


import "github.com/shirou/gopsutil/load"

//获取CPU负载信息
func getCpuLoad() {
	info, _ := load.Avg()
	fmt.Printf("%v\n", info)
}
```



​				**2.Memory**

```go
import "github.com/shirou/gopsutil/mem"

// 内存信息
func getMemInfo() {
	memInfo, _ := mem.VirtualMemory()
	fmt.Printf("mem info:%v\n", memInfo)
}
```



​				**3.Host**

```go
import "github.com/shirou/gopsutil/host"

// host info
func getHostInfo() {
	hInfo, _ := host.Info()
	fmt.Printf("host info:%v uptime:%v boottime:%v\n", hInfo, hInfo.Uptime, hInfo.BootTime)
}
```



​				**4.Disk**

```go
import "github.com/shirou/gopsutil/disk"

// 硬盘信息
func getDiskInfo() {
	parts, err := disk.Partitions(true)
	if err != nil {
		fmt.Printf("get Partitions failed, err:%v\n", err)
		return
	}
	for _, part := range parts {
		fmt.Printf("part:%v\n", part.String())
		diskInfo, _ := disk.Usage(part.Mountpoint)
		fmt.Printf("disk info:used:%v free:%v\n", diskInfo.UsedPercent, diskInfo.Free)
	}

	ioStat, _ := disk.IOCounters()
	for k, v := range ioStat {
		fmt.Printf("%v:%v\n", k, v)
	}
}
```





​				**5.net IO**

```go
import "github.com/shirou/gopsutil/net"

func getNetInfo() {
	info, _ := net.IOCounters(true)
	for index, v := range info {
		fmt.Printf("%v:%v send:%v recv:%v\n", index, v, v.BytesSent, v.BytesRecv)
	}
}
```



​				**6.net**

​					**获取本机IP 的两种方式**

```go
func GetLocalIP() (ip string, err error) {
	addrs, err := net.InterfaceAddrs()
	if err != nil {
		return
	}
	for _, addr := range addrs {
		ipAddr, ok := addr.(*net.IPNet)
		if !ok {
			continue
		}
		if ipAddr.IP.IsLoopback() {
			continue
		}
		if !ipAddr.IP.IsGlobalUnicast() {
			continue
		}
		return ipAddr.IP.String(), nil
	}
	return
}

或

// Get preferred outbound ip of this machine
func GetOutboundIP() string {
	conn, err := net.Dial("udp", "8.8.8.8:80")
	if err != nil {
		log.Fatal(err)
	}
	defer conn.Close()

	localAddr := conn.LocalAddr().(*net.UDPAddr)
	fmt.Println(localAddr.String())
	return localAddr.IP.String()
}

```



## 22.influxDB时序数据库

​			是一个开源分布式时序、事件和指标数据库。使用Go语言编写，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。

​			**用时序数据库，可以用sql语言查询，目前特别火。**

​			**官网文档**：[https://docs.influxdata.com/influxdb/v1.7/introduction/getting-started/]

​			[http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one/]

​			**下载**：[https://portal.influxdata.com/downloads/]

​			**介绍：**

​					database: 数据库   		measurement:数据表		point:数据行

​					point相当于传统数据库中的一行数据，由时间戳（time）,数据（field）,标签（tag）组成

​					Series相当于InfluxDB中一些数据的集合，在同一个database中，retention policy,measurement,tag sets完全相同的数据童淑仪一个series,同一个series的数据在物理上会按照时间顺序排列储存在一起

​			**tags和fields的区别**

​				以各个城市的气象数据为例，我们要写入influxDB，其中 北京\上海\深圳这些要作为tags

​																 温度\湿度\降雨量 这些要作为fields			



​				**版本**：我们下载的是1.x版本，就用1.x的客户端 (跟下载的版本对应)

```go
package main

import (
	"fmt"
	"log"
	"time"

	client "github.com/influxdata/influxdb1-client/v2"
)

// influxdb demo

func connInflux() client.Client {
	cli, err := client.NewHTTPClient(client.HTTPConfig{
		Addr:     "http://192.168.42.133:8086",
		Username: "admin",
		Password: "",
	})
	if err != nil {
		log.Fatal(err)
	}
	return cli
}

// query
func queryDB(cli client.Client, cmd string) (res []client.Result, err error) {
	q := client.Query{
		Command:  cmd,
		Database: "test",
	}
	if response, err := cli.Query(q); err == nil {
		if response.Error() != nil {
			return res, response.Error()
		}
		res = response.Results
	} else {
		return res, err
	}
	return res, nil
}

// insert
func writesPoints(cli client.Client) {
	//连接数据库
	bp, err := client.NewBatchPoints(client.BatchPointsConfig{
		Database:  "test",
		Precision: "s", //精度，默认ns
	})
	if err != nil {
		log.Fatalf("connect to test db failed,err:%v", err)
	}

	tags := map[string]string{"cpu": "ih-cpu"}
	fields := map[string]interface{}{
		"idle":   201.1,
		"system": 43.3,
		"user":   86.6,
	}
	//给cpu_usage表添加数据
	pt, err := client.NewPoint("cpu_usage", tags, fields, time.Now())
	if err != nil {
		log.Fatalf("client NewPoint failed,err:%v", err)
	}
	bp.AddPoint(pt)
	err = cli.Write(bp)
	if err != nil {
		log.Fatalf("client write failed,err:%v", err)
	}
	log.Println("insert success")
}

func main() {
	conn := connInflux()
	fmt.Println(conn)

	// insert
	writesPoints(conn)

	// 获取10条数据并展示
	qs := fmt.Sprintf("SELECT * FROM %s LIMIT %d", "cpu_usage", 10)
	res, err := queryDB(conn, qs)
	if err != nil {
		log.Fatal(err)
	}

	for _, row := range res[0].Series[0].Values {
		for j, value := range row {
			log.Printf("j:%d value:%v\n", j, value)
		}
	}
}
```





## 23.grafana 展示信息

​		**展示数据的工具，监控数据可视化,支持很多种数据源，丰富的图标和插件。最新的版本也支持告警功能**

​		后端使用Go开发，支持类似SQL的查询方式

​				**官网**：[https://grafana.com/grafana/download?platform=windows]

```go
1.修改配置文件：
复制 conf\defaults.ini 生成 custom.ini 文件

2.启动服务：
bin\grafana-server.exe

3.客户端访问网站：
192.168.42.133:3000
默认用户名：admin  密码：admin

```

```
(使用Kafka、Elasticsearch、Grafana搭建业务监控系统)[https://blog.csdn.net/tonywu1992/article/details/83506671]
```

​	



## 24.两个项目的架构图

**分别为：日志收集系统架构图（Log Agent -> Kafka ->log transfer->ES->Kibana->浏览器）**

​				**收集系统信息架构图 （Sys Agent（gopsutil包收集服务器性能信息）->Kafka->sys transfer->influxDB->Grafana->浏览器）** 

注：1.**收集系统信息的简单项目**：（F:\Learn\Go\GOWork\src\code.oldbody.com\studygolang\mylearn\16grafana_demo\collect）

​		2.系统信息为什么要先写到kafka里面，再发送到influxdb。不能直接发送到influxdb吗？

​			因为influxdb集群是收费的，为了防止长期的数据出现丢失现象，先放入kafka中备份，在发送到influxdb中。如果出现数据延时的问题，可以多起几个goroutine,减少数据传递间隔

![](C:\Users\Administrator\Desktop\images\项目结构图.png)

**SysAgent中的 SysTransfer工作流程：( kafka消费者->channel->写入influxdb)**

![](C:\Users\Administrator\Desktop\images\sysagent.png)



## 25.ES（Elasticsearch）

​		**是一个分布式，restful风格的搜索和数据分析引擎**，能够解决不断涌现的各种用例。作为 Elastic Stack的核心，他集中存储您的数据，帮您发现意料之中及意料之外的情况。

​		**开源的搜索引擎**，java开发，基于Lucene

​		**倒排索引（reversed index）** 

​		（Near Realtime）NRT:几乎实时 ； Cluster集群 ； Node节点 ; Index索引 ； 。。。

​		官网：[https://www.elastic.co/cn/products/elasticsearch]

​		**ES API**：使用`curl`演示操作。[https://www.liwenzhou.com/posts/Go/go_elasticsearch/]

​		**因为使用 curl 命令对ES数据库进行操作，特别麻烦，所以一般使用Kibana在web界面对ES进行操作。**

​		**注：ES 版本与Kibana版本必须一致才能使用**

​		**Go语言操作ES，使用第三方库，不用官方库**

​				https://github.com/olivere/elastic来连接ES并进行操作。

​				**注意下载与你的ES相同版本的client，**例如我们这里使用的ES是7.2.1的版本，那么我们下载的client也要与之对应为`github.com/olivere/elastic/v7`。

## 26.Kibana

​		**是一个开源的分析和可视化平台，设计用于和ES(Elasticsearch)一起工作**

​		使用kibana来搜索，查看，并和存储在ES 索引中的数据进行交互。可以轻松的执行高级数据分析，并且以各种图标，表格和地图的形式可视化数据。

​		kibana使得理解大量数据变得很容易。他简单的基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示ES查询的变化。

​		**Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。**

​		**Kibana 可以使大数据通俗易懂。它很简单，基于浏览器的界面便于您快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。**

​		**启动kibana服务，访问服务网址就可以查看kibana连接的ES数据**



## 日志收集项目总结：

​		**1.etcd 创建日志文件的配置项：**

​			项目地址：（**etcd**）[F:\Learn\Go\GOWork\src\code.oldbody.com\studygolang\mylearn\12etcd\demo\main.go]

​		**2.通过etcd获取当前日志文件配置项（日志文件目录，kafka的topic）,获取etcd监控的日志文件目录，获取日志文件内容将内容->发送到kafka**

​			项目地址：(**logagent**)(11logagent_all_ip 添加了多个服务器IP，部署到不同的服务器上，获取本机ip的功能)     [F:\Learn\Go\GOWork\src\code.oldbody.com\studygolang\mylearn\11logagent_all\main.go]

​		**3.从kafka获取日志文件内容(topic)，发送到ES搜索引擎数据库，通过Kibana网站查看日志文件**

​			项目地址：(**logtranfer**)[F:\Learn\Go\GOWork\src\code.oldbody.com\studygolang\mylearn\18logtransfer\main.go]

![](C:\Users\Administrator\Desktop\images\项目结构图.png)

​	**问题：**为什么要自己写一个logagent,不用**fileBeat**??

​				因为公司使用etcd搭了一个配置中心，所有配置都在配置中心里，通过web页面管理。如果有配置更新，可以监视etcd 进行更新；如果是fileBeat,需要修改配置，重启，挺麻烦的。

​		**fileBeat[https://github.com/elastic/logstash-forwarder]**



## 补充架构内容

​		**1.分布式ID生成 ： 雪花算法 snowflake**

​		**2.分布式锁的三种方式**

​				a.基于Redis的setnx

​				b.基于Zookeeper

​				c.基于etcd

​		**3.流量限制-令牌桶**

​				1.漏桶（常用）  2.令牌桶



## 面试题

[面试题大礼包](https://docs.qq.com/doc/DTkJ3THFtakZocWFF?opendocxfrom=admin)

[2019年面试题](https://docs.qq.com/doc/DTkJjdXJZbGZEUk1S?opendocxfrom=admin)

[快速排序\归并排序\堆排序](https://www.liwenzhou.com/posts/Go/go_algorithm/)



## Rest API

​	**通过URL定位资源，HTTP描述操作（GET POST DELETE UPDATE）**

​		**获取商品  GET /XXX/product**

​		**添加商品  POST /xxx/product**

​		**修改商品  PUT /xxx/product**

​		**删除商品  DELETE /xxx/product**

